{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_similarity",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmdUwpMv7_0w"
      },
      "source": [
        "# Downloads and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0os8w9n8GEN"
      },
      "source": [
        "## Download libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pgtBGTa41nz"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install gensim\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bdc0lb28KwQ"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks4qf5kx6ngq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "import nltk\n",
        "\n",
        "import os.path\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "import scipy\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPDPxXHu8RKF"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYwYGVo67Oea"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JREbB2Cc7W31"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXg5tntm7lCc"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz2TuooJ9D7p"
      },
      "source": [
        "glove_file = datapath('/content/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaYTxDdn9R-M"
      },
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5DPZ8nS9q9Y"
      },
      "source": [
        "word2vec.distance(\"object\", \"oriented\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVY6gNam_2zl"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QW3qKkm_6n7"
      },
      "source": [
        "texts = []\n",
        "\n",
        "for i in range(5):\n",
        "    first = ['A', 'B', 'C', 'D', 'E']\n",
        "    for j in first:\n",
        "        second = ['a', 'b', 'c', 'd', 'e']\n",
        "        for k in second:\n",
        "            filename = \"g\" + str(i) + \"p\" + j + \"_task\" + k + \".txt\"\n",
        "            filepath = \"/content/data/\" + filename\n",
        "            if os.path.isfile(filepath) == True:\n",
        "                reader = open(filepath, \"r\")\n",
        "                data = reader.read()\n",
        "                texts.append({\"file\": filename, \"data\": data})\n",
        "print(texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF5D6Ilz8Whu"
      },
      "source": [
        "# Convert to tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNBaW3J28YRS"
      },
      "source": [
        "tokenized_text = []\n",
        "for text in texts:\n",
        "    ans_remove_punc = re.sub(r'[^\\w\\s]',' ', text[\"data\"])\n",
        "    ans = word_tokenize(ans_remove_punc)\n",
        "    valid_token = []\n",
        "    for i in range(len(ans)):\n",
        "        ans[i] = ans[i].lower()\n",
        "        if ans[i] in word2vec.vocab:\n",
        "            valid_token.append(ans[i])\n",
        "        else:\n",
        "            print(\"Throwing \" + ans[i] + \" from \" + text[\"file\"])\n",
        "    tokenized_text.append({\"file\": text[\"file\"], \"tokens\": valid_token})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vFxS4FAJIRo"
      },
      "source": [
        "print(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_Fy1E4PiOW"
      },
      "source": [
        "# Find mean of word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaIZ3kN8Lqqy"
      },
      "source": [
        "vector_mean = []\n",
        "\n",
        "for i in tokenized_text:\n",
        "    vec = np.mean([word2vec[word] for word in i[\"tokens\"]], axis=0)\n",
        "    vector_mean.append({\"file\": i[\"file\"], \"vector\": vec})\n",
        "\n",
        "print(vector_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTvlb8RxQDDG"
      },
      "source": [
        "print(vector_mean[0][\"file\"][-5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh_dOBNCRNUM"
      },
      "source": [
        "#Load original text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEhT894CQfoe"
      },
      "source": [
        "original_text = []\n",
        "tasks = ['a', 'b', 'c', 'd', 'e']\n",
        "for i in tasks:\n",
        "    filename = \"orig_task\" + i + \".txt\"\n",
        "    filepath = \"/content/data/\" + filename\n",
        "    reader = open(filepath, \"r\")\n",
        "    data = reader.read()\n",
        "    original_text.append({\"task\": i, \"data\": data})\n",
        "print(original_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfVo5MPRHxQ"
      },
      "source": [
        "original_tokenized = []\n",
        "for task in original_text:\n",
        "    ans_remove_punc = re.sub(r'[^\\w\\s]',' ', task[\"data\"])\n",
        "    ans = word_tokenize(ans_remove_punc)\n",
        "    valid_token = []\n",
        "    for i in range(len(ans)):\n",
        "        ans[i] = ans[i].lower()\n",
        "        if ans[i] in word2vec.vocab:\n",
        "            valid_token.append(ans[i])\n",
        "        else:\n",
        "            print(\"Throwing \" + ans[i] + \" from \" + task[\"task\"])\n",
        "    original_tokenized.append({\"task\": task[\"task\"], \"tokens\": valid_token})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu2anvGzRvzr"
      },
      "source": [
        "print(original_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wiLIgtoSBm-"
      },
      "source": [
        "original_vectors = []\n",
        "for task in original_tokenized:\n",
        "    vec = np.mean([word2vec[word] for word in task[\"tokens\"]], axis=0)\n",
        "    original_vectors.append({\"task\": task[\"task\"], \"vector\": vec})"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCaGRR7rSdJK"
      },
      "source": [
        "print(original_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX6ewDTtTSzu"
      },
      "source": [
        "#Predict results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHuiQiwkSjzQ"
      },
      "source": [
        "results = []\n",
        "\n",
        "for text in vector_mean:\n",
        "    for original in original_vectors:\n",
        "        if text[\"file\"][-5] == original[\"task\"]:\n",
        "            cosine = scipy.spatial.distance.cosine(text[\"vector\"], original[\"vector\"])\n",
        "            results.append({\"file\": text[\"file\"], \"distance\": cosine * 100})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klqv9wm-TNET"
      },
      "source": [
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXOoe-RQTV4v"
      },
      "source": [
        "results_df = pd.DataFrame(results)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uxHlm6iUZ9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cc3aa8c7-1740-4518-9703-68ba725727db"
      },
      "source": [
        "results_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>g0pA_taska.txt</td>\n",
              "      <td>1.762670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>g0pA_taskb.txt</td>\n",
              "      <td>0.498301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>g0pA_taskc.txt</td>\n",
              "      <td>0.185782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>g0pA_taskd.txt</td>\n",
              "      <td>1.569027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>g0pA_taske.txt</td>\n",
              "      <td>0.998652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             file  distance\n",
              "0  g0pA_taska.txt  1.762670\n",
              "1  g0pA_taskb.txt  0.498301\n",
              "2  g0pA_taskc.txt  0.185782\n",
              "3  g0pA_taskd.txt  1.569027\n",
              "4  g0pA_taske.txt  0.998652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWwY4LfuUCTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "09877847-9124-4656-eafc-4bffdea47acb"
      },
      "source": [
        "results_df.to_csv('result.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('result.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_35d6b5c4-9028-41ab-85ad-c3fc142ba5d4\", \"result.csv\", 3244)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS2tUQLhg11Q"
      },
      "source": [
        "# Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giX2um3uUduS"
      },
      "source": [
        "labels = pd.read_excel(\"./corpus-final09.xls\", sheet_name=\"File list\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "HQMGPrlCg097",
        "outputId": "54eb4e76-4104-42e5-e872-4e5979a08a5c"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Group</th>\n",
              "      <th>Person</th>\n",
              "      <th>Task</th>\n",
              "      <th>Category</th>\n",
              "      <th>Native English</th>\n",
              "      <th>Knowledge</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>g0pA_taska.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>a</td>\n",
              "      <td>non</td>\n",
              "      <td>native</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>g0pA_taskb.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>b</td>\n",
              "      <td>cut</td>\n",
              "      <td>native</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>g0pA_taskc.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>c</td>\n",
              "      <td>light</td>\n",
              "      <td>native</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>g0pA_taskd.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>d</td>\n",
              "      <td>heavy</td>\n",
              "      <td>native</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>g0pA_taske.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>e</td>\n",
              "      <td>non</td>\n",
              "      <td>native</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             File  Group Person  ... Native English Knowledge Difficulty\n",
              "0  g0pA_taska.txt      0      A  ...         native         1          1\n",
              "1  g0pA_taskb.txt      0      A  ...         native         4          3\n",
              "2  g0pA_taskc.txt      0      A  ...         native         5          3\n",
              "3  g0pA_taskd.txt      0      A  ...         native         3          4\n",
              "4  g0pA_taske.txt      0      A  ...         native         4          3\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfvubOAg-tt"
      },
      "source": [
        "results_list = []\n",
        "for index1, row1 in labels.iterrows():\n",
        "    for index2, row2 in results_df.iterrows():\n",
        "        if row1[\"File\"] == row2[\"file\"]:\n",
        "            results_list.append({\"file\": row1[\"File\"], \"type\": row1[\"Category\"], \"distance\": row2[\"distance\"]})"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF40lO3ChAsV"
      },
      "source": [
        "def get_results(results_list, threshhold):\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    total_positive = 0\n",
        "    total_negative = 0\n",
        "    for i in range(len(results_list)):\n",
        "        if results_list[i][\"distance\"] <= threshhold:\n",
        "            if results_list[i][\"type\"] == \"non\":\n",
        "                false_positive += 1\n",
        "                total_negative += 1\n",
        "            else:\n",
        "                true_positive += 1\n",
        "                total_positive += 1\n",
        "        else:\n",
        "            if results_list[i][\"type\"] == \"non\":\n",
        "                true_negative += 1\n",
        "                total_negative += 1\n",
        "            else:\n",
        "                false_negative += 1\n",
        "                total_positive += 1\n",
        "    return true_positive, true_negative, false_positive, false_negative\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH2d9y-DhU0W"
      },
      "source": [
        "def get_score(true_positive, true_negative, false_positive, false_negative):\n",
        "    accuracy = (true_positive + true_negative) / (total_positive + total_negative)\n",
        "    precision = true_positive / (true_positive + true_negative)\n",
        "    recall = true_positive / (true_positive + false_negative)\n",
        "    f_score = 2 * precision * recall / (precision + recall)\n",
        "    return accuracy, f_score\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0r6rRHghW4o",
        "outputId": "109586ef-3c00-4ff4-a1c9-4972a1464715"
      },
      "source": [
        "true_positive, true_negative, false_positive, false_negative = get_results(results_list, threshhold=1.0)\n",
        "accuracy, f_score = get_score(true_positive, true_negative, false_positive, false_negative)\n",
        "print(\"Total positives: \" + str(total_positive))\n",
        "print(\"Total negatives: \" + str(total_negative))\n",
        "print(\"False positive: \" + str(false_positive))\n",
        "print(\"False negative: \" + str(false_negative))\n",
        "print(\"True positive: \" + str(true_positive))\n",
        "print(\"True negative: \" + str(true_negative))\n",
        "print(\"Accuracy: \" + str(accuracy))\n",
        "print(\"f_score: \" + str(f_score))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total positives: 57\n",
            "Total negatives: 38\n",
            "False positive: 15\n",
            "False negative: 14\n",
            "True positive: 43\n",
            "True negative: 23\n",
            "Accuracy: 0.6947368421052632\n",
            "f_score: 0.6991869918699187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWJj06YdiIPS",
        "outputId": "fcb68464-def4-44bb-d760-e8771cbc00ce"
      },
      "source": [
        "bestthreshhold = 1.0\n",
        "bestscore = 0.6947368421052632\n",
        "trythreshhold=0.9\n",
        "while trythreshhold <= 2:\n",
        "    true_positive, true_negative, false_positive, false_negative = get_results(results_list, threshhold=trythreshhold)\n",
        "    accuracy, f_score = get_score(true_positive, true_negative, false_positive, false_negative)\n",
        "    if accuracy > bestscore:\n",
        "        bestscore = accuracy\n",
        "        bestthreshhold = trythreshhold\n",
        "        print(str(trythreshhold) + \" beats with score \" + str(bestscore))\n",
        "    trythreshhold += 0.001"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9920000000000001 beats with score 0.7052631578947368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy2I8Lz3ixFR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}